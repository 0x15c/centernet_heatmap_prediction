# CenterNet Heatmap Prediction for Marker Detection in Tactile Sensing

We are trying to predict a heatmap of pseudo probability distribution of markers, from the raw image of a tactile sensor, for example, the [D-Sight](https://github.com/0x15c/D-Sight). This repo is still under construction; however, we have obtained some promising results from [CenterNet](http://arxiv.org/abs/1904.07850).


We use ResNet-9 as the backbone for feature extraction; it's a lightweight alternative, producing only ~11.5 MB model. We believe inference can be accelerated using light models while feature extraction ability is preserved, due to our rather simple sensor output (we are not expecting the model to recognise complex features, such as an animal). Here is a [link](https://github.com/Moddy2024/ResNet-9.git) to the ResNet-9 implementation.

Below is an image of mixed raw sensor output and predicted marker distribution.

CenterNet probability distribution over input image             |  Extracted keypoints
:-------------------------:|:-------------------------:
![inference](imgs/inference.png "inference result ") |  ![keypoints](imgs/orb_features.png "orb features")


The [VoxelMorph](https://arxiv.org/abs/1809.05231) code is employed in our code to predict the *marker displacement field* (To see why this problem is important in tactile sensing, check [this review paper](https://doi.org/10.1109/JSEN.2023.3255861)). As a successful approach generating dense displacement field from given n-D {fixed, moving} voxelmap pair, voxelmorph converts the hard optimization-based image registrtation problem into a function-based one, resulting in its high efficiency and accuracy when trained and evaluated on a given distribution of dataset. The training of voxelmorph does not need ground truth displacement field, as it is difficult to obtain; however the supervise signal is directly generated by the loss function, which punishes the simularity of image pair and the smothness of displacement field, in its derivative norms.

We rewrite the logic of voxelmorph to make it focused on 2D image registration. The pointwise displacement vector is calculated out of mean flow field within an area centered on that pixel. Below is an image of the vector arrows. The green dots are those estimated marker centroids in their initial position, and the red ones show the moved centroids. The arrows illustrate the direction and magnitude of the displacement field. Our code can run ~28 FPS on a workstation PC (AMD R9-9900X, RTX 5070Ti GPU), with video resolution of 640x360. The performance bottleneck is at the centernet prediction stage.

![displacement](imgs/disp.png)
